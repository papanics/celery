packages we use:
1.Celery
2.Django Celery Beat
3. Django Celery Results


What is Celery?
- a task queue for executing work outside a Python web application HTTP request-response cycle.
-A task queue's input is a unit of work called a task. Didicated worker processes constantly monitor task queues for
new  work to perform.
-Celery is written in Python, but the protocol can be implemented in any lanugae. In a addition to Python, there's
node-celery and node-celery-ts for Node.js, and a PHP client.
-Broker(taskque) -> ex. Redis, RabbitMQ, Amazon SQS 
-FIFO --> t1,t2,t3
-schedule a task in every 30secs that send an API request to the Third party API to update our database.
-serialization ex. pickle, json, yaml, msgpack
-1 worker has a multiple worker

What is celery Beat? 
-task scheduler

what is -django-celery-results package? 
-store celery results to the Django database.
-Query and display automatically to the django admin panel.

why to use celery?
-Suppose we need to access API every minute (hour),
 or we want to send multiple emails at the end of the day. 
 Celery can schedule that type of periodic task easily.
-Third party API calls.
-For High CPU intensive tasks.
-Periodic/scheduled Tasks.
-For improving the User Experience.
-Reduce extra over workload.
-asynchronous

Why celery if we have multithreading, async, and multiprocessing?

Celery execution pool implementations:
-prefork(multiprocessing)[default]
-solo
-threads(multithreading)
-eventlet
-gevent

start celery command
-$ celery -A <project>.celery worker -l info
-by default, pool - prefork and condurrency - no. of cores
-celery -A <project>.celery worker --pool=solo -l info
-celery -A <project>.celery worker --concurrency=5 -l info


Celery basic setup

Big word 
CELERY - instead of django will perform the task, the celery can do that job or perform the task

1.pip install celery
 


2. add these celery settings to the settings.py 

CELERY_BROKER_URL = 'redis://127.0.0.1:6379'
accept_content = ['application/json']
CELERY_RESULT_SERIALIZER = 'json'
CELERY_TASK_SERIALIZER = 'json'
CELERY_TIMEZONE = 'Asia/Manila'

CELERY_RESULT_BACKEND = 'django-db'


3. install redis 
 - search to google redis windows github and download redis-x64-versions.msi
 -to test the redis
    -go to c>programfiles>redis then run the redis-cli.exe 
    -type ping then it will response a PONG.


4. add celery.py file to the project folder and add these settings

from __future__ import absolute_import, unicode_literals
from concurrent.futures.thread import _worker
from lib2to3.pytree import _Results
import os


from celery import Celery
from django.conf import settings

from celery_proj.settings import INSTALLED_APPS

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'celery_proj.settings')

app = Celery('celery_proj')
app.conf.enable_utc = False

app.conf.update(timezone = 'Asia/Manila')

app.config_from_object(settings, namespace='CELERY')

#Celery Beat settings
app.conf.beat_schdeule = {
    
}

app.autodiscover_tasks(lambda: settings.INSTALLED_APPS)

@app.task(bind=True)
def debug_task(self):
    print(f'Request: {self.request!r}')



5. add task.py to the app folder

from celery import shared_task

@shared_task(bind=True)
def test_func(self):
    #operations

    for i in range(10):
        print(i)
    return "Done"

6. start the celery worker
celery -A project_name.celery worker --pool=solo -l info

7.pip install django-celery-results

8.add to INSTALLED_APPS
-'app',
-'django_celery_results'

9.migrate the data
-python manage.py makemigrations
-python manage.py migrate

10. add this to __init__.py

from .celery import app as app_celery

__all__ = ('app_celery',)

11. pip install django-celery-beat

12. start the celery beat on the cmd
-apply migrations first 
-celery -A celery_proj beat -l INFO